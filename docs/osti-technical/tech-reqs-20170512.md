# 20170512 Technical Meeting

**Date: May 12, 2017**

**Time: 11:00 a.m. - 12:00 p.m.**

**Agenda:**
1.	AWS
2. Dark Archiving

**Proceedings:**

1.	The meeting began with a brief discussion about AWS. Last week, the project lead was able to get DOE Code working on AWS. He was unable to access client, but it worked great otherwise-no firewall issue and the server and YAML file worked really well. The group that he was presenting to were impressed with the accordion-style form and the validation while completing fields in the form. Developers have plans to look more into AWS next week to work toward getting the client working. 

2.	The rest of the meeting was spent focusing on dark archiving. The current status on dark archiving was to take the repo link, git/svn,  code it and put in cache area. An issue with cloning into another GitLab instance was that it requested an API level key. Another interesting problem with GitLab is that you cannot have projects with the same name in the same organization. An action item coming from this discussion was to try some different scenarios with the Git-line tool and see what can be done on the backend. 

    Next, the team discussed the concept of a trinary archive. This would be relevant for hosting repositories last resort and for the       ‘brightening’ scenario. The Full-Dark archive would be internal to OSTI and all of it gets backed up. It would pull from unlimited  GitLab and limited GitLab instances. A question was asked of why to have the Full-Dark archive in GitLab if no one can access it. An action item coming from this was to figure out how much does using GitLab at the Dark-Archive level make sense and to go over the    advantages and disadvantages of using GitLab for it.  
   
    The last part of the dark-archiving conversation was spent going over practical issues. For subversion client, the plan would be to do a subversion git bridge to get everything, then convert. This brought about the question of should the repo be retrieved on subversion or be done separately (synchronously or asynchronously) – check git repo then or launch separate thread? With the amount of processing that could be required, it was suggested to have a third service. Full workflow diagrams and sequence diagrams have been sketched out for the separate service (archival server) – linked below. 
- [ArchiveScheme1]( https://github.com/doecode/doecode/blob/master/docs/osti-technical/Archive%20Schema%20Photos/ArchiveScheme1.jpg)
-	[ArchiveScheme2]( https://github.com/doecode/doecode/blob/master/docs/osti-technical/Archive%20Schema%20Photos/ArchiveScheme2.jpg)
-	[ArchiveScheme3]( https://github.com/doecode/doecode/blob/master/docs/osti-technical/Archive%20Schema%20Photos/ArchiveScheme3.jpg)
-	[ArchiveScheme4]( https://github.com/doecode/doecode/blob/master/docs/osti-technical/Archive%20Schema%20Photos/ArchiveScheme4.jpg)

**Actions:**
 - Review ticket on client on AWS and GitHub keys
 - Try some scenarios with Git-line tool and see what can be done on backend
 - Figure out if we need something like GitLab at the dark-archive level
 - Develop sequence diagrams for archival server

